{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#old data, no generator, less crop doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Lambda, Flatten\n",
    "from keras.layers.convolutional import Conv2D, Cropping2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "import sys\n",
    "\n",
    "#print(K.image_data_format())\n",
    "#'channels_first'\n",
    "#K.set_image_data_format('channels_last')\n",
    "#print(K.image_data_format())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27242, 7)\n",
      "(25000, 7)\n",
      "(2242, 7)\n"
     ]
    }
   ],
   "source": [
    "split_fraction = 25000\n",
    "\n",
    "all_data = pd.read_csv(\"mydata2/driving_log.csv\", names = [\"center\", \"left\", \"right\", \"Steering\", \"throtle\", \"something\",\"speed\"])\n",
    "all_data_shuffled = shuffle(all_data)\n",
    "\n",
    "print (all_data.shape)\n",
    "\n",
    "training_data = all_data_shuffled[:split_fraction]\n",
    "validation_data = all_data_shuffled[split_fraction:]\n",
    "\n",
    "print (training_data.shape)\n",
    "print (validation_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generator\n",
    "def driving_generator(working_data):\n",
    "    # creating generator that gives always balanced batches\n",
    "    \n",
    "    pandas_batch = pd.DataFrame()\n",
    "    images_list = []\n",
    "    new_list = shuffle(working_data)\n",
    "    \n",
    "    max_steering = new_list.iloc[:,[3]].max()\n",
    "    max_steering = max_steering.as_matrix()[0]\n",
    "\n",
    "    min_steering = new_list.iloc[:,[3]].min()\n",
    "    min_steering = min_steering.as_matrix()[0]\n",
    "    \n",
    "    buckets = 32\n",
    "    \n",
    "    print(\"max\", max_steering)\n",
    "    print(\"min\", min_steering)\n",
    "\n",
    "    step = abs((min_steering - max_steering) / buckets)\n",
    "    print (\"step\", step)\n",
    "\n",
    "    steering_range_low = min_steering\n",
    "    steering_range_high = 0\n",
    "    \n",
    "    while True:\n",
    "        steering_range_low = min_steering\n",
    "        steering_range_high = 0\n",
    "        for i in range(buckets):\n",
    "\n",
    "                steering_range_high = steering_range_low + step\n",
    "                #print (\"high\",steering_range_high,\"low\", steering_range_low)\n",
    "                bucket_list = new_list[(new_list.Steering >= steering_range_low) & (new_list.Steering < steering_range_high)]\n",
    "                bucket_quantity = len(bucket_list)\n",
    "                if bucket_quantity >0:\n",
    "                    chosen = bucket_list.sample(1)\n",
    "                    #print (chosen)\n",
    "                    steering_range_low += step\n",
    "                    pandas_batch = pandas_batch.append(chosen)\n",
    "        #print (pandas_batch.shape)\n",
    "\n",
    "        names = pandas_batch.iloc[:,[0]].as_matrix()[:,0]\n",
    "        steering = pandas_batch.iloc[:,[3]].as_matrix()[:,0]\n",
    "        #print (\"names\",names)\n",
    "        #print (\"steering\", steering)\n",
    "\n",
    "        for name in names:\n",
    "            #print (name)\n",
    "            #print (name.split('\\\\'))\n",
    "            if name.startswith('/'):\n",
    "                #print (name[0].split('/'))\n",
    "                splited_name = name.split('/')\n",
    "                path = 'mydata2/IMG/'+splited_name[9]\n",
    "                #print (\"media\",path)\n",
    "            else:\n",
    "                #print (name.split('\\\\'))\n",
    "                splited_name = name.split('\\\\')\n",
    "                path = 'mydata2/IMG/'+splited_name[6]\n",
    "                #print (path)\n",
    "\n",
    "            image = cv2.imread(path)\n",
    "            image = image[...,::-1] #conversion to rgb\n",
    "            #plt.imshow(image)\n",
    "            #plt.show()\n",
    "            #print(image)\n",
    "            images_list.append(image)\n",
    "\n",
    "        X_train = np.array(images_list)\n",
    "        y_train = np.expand_dims(steering, axis=1)\n",
    "\n",
    "        pandas_batch = pd.DataFrame()\n",
    "        images_list = []\n",
    "        #print (X_train, y_train)\n",
    "        #print (\"\\n\\n\")\n",
    "        # unpack batch properly\n",
    "        yield (X_train, y_train)\n",
    "\n",
    "#franek = driving_generator(training_data)\n",
    "#next(franek)\n",
    "#next(franek)\n",
    "#raise SystemExit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "max 0.3838028\n",
      "min -0.4047619\n",
      "step 0.024642646875\n",
      " 999/1000 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.0021- Emax 0.3392018\n",
      "min -0.3556548\n",
      "step 0.02171426875\n",
      "1000/1000 [==============================] - 183s - loss: 0.1118 - acc: 0.0021 - val_loss: 0.0010 - val_acc: 0.0000e+00\n",
      "Epoch 2/4\n",
      "1000/1000 [==============================] - 107s - loss: 8.5545e-04 - acc: 0.0022 - val_loss: 0.0015 - val_acc: 0.0000e+00\n",
      "Epoch 3/4\n",
      "1000/1000 [==============================] - 106s - loss: 5.8393e-04 - acc: 0.0021 - val_loss: 0.0013 - val_acc: 0.0000e+00\n",
      "Epoch 4/4\n",
      "1000/1000 [==============================] - 105s - loss: 4.7439e-04 - acc: 0.0018 - val_loss: 2.9895e-04 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def nvidia_model():\n",
    "    model = Sequential()\n",
    "    nv_model = Sequential()\n",
    "    nv_model.add (Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "    nv_model.add (Cropping2D(cropping=((20,20), (0,0)), input_shape=(160,320,3)))\n",
    "    \n",
    "    nv_model.add (Conv2D(24, (5,5), strides=1, padding=\"valid\"))\n",
    "    nv_model.add (ELU())\n",
    "    nv_model.add ((MaxPooling2D(pool_size=(2,2))))\n",
    "\n",
    "    nv_model.add (Conv2D(36, (5,5), strides=1, padding=\"valid\"))\n",
    "    nv_model.add (ELU())\n",
    "    nv_model.add ((MaxPooling2D(pool_size=(2,2))))\n",
    "        \n",
    "    nv_model.add (Conv2D(48, (5,5), strides=1, padding=\"valid\"))\n",
    "    nv_model.add (ELU())\n",
    "    nv_model.add ((MaxPooling2D(pool_size=(2,2))))\n",
    "    \n",
    "    nv_model.add (Conv2D(64, (3,3), strides=1, padding=\"valid\"))\n",
    "    nv_model.add (ELU())\n",
    "    \n",
    "    nv_model.add (Conv2D(64, (3,3), strides=1, padding=\"valid\"))\n",
    "    nv_model.add (ELU())\n",
    "    \n",
    "     \n",
    "    nv_model.add(Flatten())\n",
    "    nv_model.add(Dense(1164))\n",
    "    nv_model.add(ELU())\n",
    "    nv_model.add(Dense(100))\n",
    "    nv_model.add(ELU())\n",
    "    nv_model.add(Dense(50))\n",
    "    nv_model.add(ELU())\n",
    "    nv_model.add(Dense(10))\n",
    "    nv_model.add(ELU())\n",
    "    \n",
    "    nv_model.add(Dense(1, activation=\"linear\"))\n",
    "    nv_model.compile(optimizer=\"adam\", metrics=['accuracy'], loss=\"mse\")\n",
    "    return nv_model\n",
    "\n",
    "my_model = nvidia_model()\n",
    "\n",
    "\n",
    "# zmienic zeby validation pracowalo na valid data\n",
    "training_generator = driving_generator(training_data)\n",
    "validation_generator = driving_generator(validation_data)\n",
    "\n",
    "#my_model.fit(X_train, y_train,  validation_data=(X_valid,y_valid), shuffle=True, batch_size=32, epochs=5, verbose=1)\n",
    "#model.fit_generator(train_generator, samples_per_epoch= /\n",
    "          #  len(train_samples), validation_data=validation_generator, /\n",
    "          #  nb_val_samples=len(validation_samples), nb_epoch=3)\n",
    "        \n",
    "my_model.fit_generator(training_generator,  validation_data=validation_generator, validation_steps=(validation_data.shape[0] // 32), steps_per_epoch=1000, epochs=4, verbose=1)\n",
    "my_model.save(\"model.h5\")\n",
    "#score = model.evaluate(x_test, y_test, batch_size=32)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
